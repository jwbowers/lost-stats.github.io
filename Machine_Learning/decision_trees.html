
<!DOCTYPE html>
<html lang="en-US">
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge">
  <link rel="stylesheet" href="/assets/css/just-the-docs-default.css">
  <link rel="stylesheet" href="/assets/css/just-the-docs-head-nav.css" id="jtd-head-nav-stylesheet">
  <style id="jtd-nav-activation">
    .site-nav > ul.nav-list:first-child > li > a,
    .site-nav > ul.nav-list:first-child > li > ul > li:not(:nth-child(5)) > a,
    .site-nav > ul.nav-list:first-child > li > ul > li > ul > li a {
      background-image: none;
    }
    .site-nav > ul.nav-list:not(:first-child) a,
    .site-nav li.external a {
      background-image: none;
    }
    .site-nav > ul.nav-list:first-child > li:nth-child(3) > ul > li:nth-child(5) > a {
      font-weight: 600;
      text-decoration: none;
    }.site-nav > ul.nav-list:first-child > li:nth-child(3) > button svg,
    .site-nav > ul.nav-list:first-child > li:nth-child(3) > ul > li:nth-child(5) > button svg {
      transform: rotate(-90deg);
    }.site-nav > ul.nav-list:first-child > li.nav-list-item:nth-child(3) > ul.nav-list,
    .site-nav > ul.nav-list:first-child > li.nav-list-item:nth-child(3) > ul.nav-list > li.nav-list-item:nth-child(5) > ul.nav-list {
      display: block;
    }
  </style>
    <script src="/assets/js/vendor/lunr.min.js"></script>
  <script src="/assets/js/just-the-docs.js"></script>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="icon" href="/favicon.ico" type="image/x-icon">
  <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Decision Trees | LOST</title>
<meta name="generator" content="Jekyll v4.4.0" />
<meta property="og:title" content="Decision Trees" />
<meta property="og:locale" content="en_US" />
<meta property="og:site_name" content="LOST" />
<script type="application/ld+json">
{"url":"/Machine_Learning/decision_trees.html","@type":"WebPage","headline":"Decision Trees","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "AMS" } } });
  </script>
  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_CHTML">
  </script>
</head>
<body>
  <a class="skip-to-main" href="#main-content">Skip to main content</a>
  <svg xmlns="http://www.w3.org/2000/svg" class="d-none">
  <symbol id="svg-link" viewBox="0 0 24 24">
  <title>Link</title>
  <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link">
    <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path>
  </svg>
</symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
  <title>Menu</title>
  <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu">
    <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line>
  </svg>
</symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
  <title>Expand</title>
  <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right">
    <polyline points="9 18 15 12 9 6"></polyline>
  </svg>
</symbol>
  <!-- Feather. MIT License: https://github.com/feathericons/feather/blob/master/LICENSE -->
<symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link">
  <title id="svg-external-link-title">(external link)</title>
  <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line>
</symbol>
    <symbol id="svg-doc" viewBox="0 0 24 24">
  <title>Document</title>
  <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file">
    <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline>
  </svg>
</symbol>
    <symbol id="svg-search" viewBox="0 0 24 24">
  <title>Search</title>
  <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search">
    <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line>
  </svg>
</symbol>
    <!-- Bootstrap Icons. MIT License: https://github.com/twbs/icons/blob/main/LICENSE.md -->
<symbol id="svg-copy" viewBox="0 0 16 16">
  <title>Copy</title>
  <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16">
    <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/>
    <path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/>
  </svg>
</symbol>
<symbol id="svg-copied" viewBox="0 0 16 16">
  <title>Copied</title>
  <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16">
    <path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/>
    <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/>
  </svg>
</symbol>
</svg>
    <div class="side-bar">
  <div class="site-header" role="banner">
    <a href="/" class="site-title lh-tight">
  LOST
</a>
    <button id="menu-button" class="site-button btn-reset" aria-label="Toggle menu" aria-pressed="false">
      <svg viewBox="0 0 24 24" class="icon" aria-hidden="true"><use xlink:href="#svg-menu"></use></svg>
    </button>
  </div>
  <nav aria-label="Main" id="site-nav" class="site-nav">
    <ul class="nav-list"><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Data Manipulation category" aria-pressed="false">
        <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg>
      </button><a href="/Data_Manipulation/data_manipulation.html" class="nav-list-link">Data Manipulation</a><ul class="nav-list"><li class="nav-list-item"><a href="/Data_Manipulation/Regular_Expressions.html" class="nav-list-link">Regular Expressions</a></li><li class="nav-list-item"><a href="/Data_Manipulation/collapse_a_data_set.html" class="nav-list-link">Collapse a Data Set</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Combining Datasets category" aria-pressed="false">
        <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg>
      </button><a href="/Data_Manipulation/Combining_Datasets/combining_datasets_overview.html" class="nav-list-link">Combining Datasets</a><ul class="nav-list"><li class="nav-list-item"><a href="/Data_Manipulation/Combining_Datasets/combining_datasets_vertical_combination.html" class="nav-list-link">Vertical Combination</a></li><li class="nav-list-item"><a href="/Data_Manipulation/Combining_Datasets/combining_datasets_horizontal_merge_deterministic.html" class="nav-list-link">Horizontal Combination (Deterministic)</a></li></ul></li><li class="nav-list-item"><a href="/Data_Manipulation/creating_a_variable_with_group_calculations.html" class="nav-list-link">Creating a Variable with Group Calculations</a></li><li class="nav-list-item"><a href="/Data_Manipulation/creating_categorical_variables.html" class="nav-list-link">Creating Categorical Variables</a></li><li class="nav-list-item"><a href="/Data_Manipulation/Creating_Dummy_Variables/creating_dummy_variables.html" class="nav-list-link">Creating Dummy Variables</a></li><li class="nav-list-item"><a href="/Data_Manipulation/determine_the_observation_level_of_a_data_set.html" class="nav-list-link">Determine the Observation Level of a Data Set</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Reshaping Data category" aria-pressed="false">
        <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg>
      </button><a href="/Data_Manipulation/Reshaping/reshape.html" class="nav-list-link">Reshaping Data</a><ul class="nav-list"><li class="nav-list-item"><a href="/Data_Manipulation/Reshaping/reshape_panel_data_from_wide_to_long.html" class="nav-list-link">Reshape Panel Data from Wide to Long</a></li><li class="nav-list-item"><a href="/Data_Manipulation/Reshaping/reshape_panel_data_from_long_to_wide.html" class="nav-list-link">Reshape Panel Data from Long to Wide</a></li></ul></li><li class="nav-list-item"><a href="/Data_Manipulation/rowwise_calculations.html" class="nav-list-link">Rowwise Calculations</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Geo-Spatial category" aria-pressed="false">
        <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg>
      </button><a href="/Geo-Spatial/Geo-spatial.html" class="nav-list-link">Geo-Spatial</a><ul class="nav-list"><li class="nav-list-item"><a href="/Geo-Spatial/choropleths.html" class="nav-list-link">Choropleths</a></li><li class="nav-list-item"><a href="/Geo-Spatial/geocoding.html" class="nav-list-link">Geocoding</a></li><li class="nav-list-item"><a href="/Geo-Spatial/handling_raster_data.html" class="nav-list-link">Handling Raster Data</a></li><li class="nav-list-item"><a href="/Geo-Spatial/merging_shape_files.html" class="nav-list-link">Merging Shape Files</a></li><li class="nav-list-item"><a href="/Geo-Spatial/spatial_joins.html" class="nav-list-link">Spatial Joins</a></li><li class="nav-list-item"><a href="/Geo-Spatial/spatial_lag_model.html" class="nav-list-link">Spatial Lag Model</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Machine Learning category" aria-pressed="false">
        <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg>
      </button><a href="/Machine_Learning/Machine_Learning.html" class="nav-list-link">Machine Learning</a><ul class="nav-list"><li class="nav-list-item"><a href="/Machine_Learning/Nearest_Neighbor.html" class="nav-list-link">K-Nearest Neighbor Matching</a></li><li class="nav-list-item"><a href="/Machine_Learning/artificial_neural_network.html" class="nav-list-link">Artificial Neural Network</a></li><li class="nav-list-item"><a href="/Machine_Learning/boosted_regression_trees.html" class="nav-list-link">Boosted Regression Trees</a></li><li class="nav-list-item"><a href="/Machine_Learning/causal_forest.html" class="nav-list-link">Causal Forest</a></li><li class="nav-list-item"><a href="/Machine_Learning/decision_trees.html" class="nav-list-link">Decision Trees</a></li><li class="nav-list-item"><a href="/Machine_Learning/penalized_regression.html" class="nav-list-link">Penalized Regression</a></li><li class="nav-list-item"><a href="/Machine_Learning/random_forest.html" class="nav-list-link">Random Forest</a></li><li class="nav-list-item"><a href="/Machine_Learning/support_vector_machine.html" class="nav-list-link">Support Vector Machine</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Model Estimation category" aria-pressed="false">
        <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg>
      </button><a href="/Model_Estimation/Model_Estimation.html" class="nav-list-link">Model Estimation</a><ul class="nav-list"><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Ordinary Least Squares category" aria-pressed="false">
        <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg>
      </button><a href="/Model_Estimation/OLS/OLS.html" class="nav-list-link">Ordinary Least Squares</a><ul class="nav-list"><li class="nav-list-item"><a href="/Model_Estimation/OLS/ANOVA.html" class="nav-list-link">ANOVA</a></li><li class="nav-list-item"><a href="/Model_Estimation/OLS/simple_linear_regression.html" class="nav-list-link">Simple Linear Regression</a></li><li class="nav-list-item"><a href="/Model_Estimation/OLS/stepwise_regression.html" class="nav-list-link">Stepwise Regression</a></li><li class="nav-list-item"><a href="/Model_Estimation/OLS/interaction_terms_and_polynomials.html" class="nav-list-link">Interaction Terms and Polynomials</a></li><li class="nav-list-item"><a href="/Model_Estimation/OLS/fixed_effects_in_linear_regression.html" class="nav-list-link">Fixed Effects in Linear Regression</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Matching category" aria-pressed="false">
        <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg>
      </button><a href="/Model_Estimation/Matching/matching.html" class="nav-list-link">Matching</a><ul class="nav-list"><li class="nav-list-item"><a href="/Model_Estimation/Matching/entropy_balancing.html" class="nav-list-link">Entropy Balancing</a></li><li class="nav-list-item"><a href="/Model_Estimation/Matching/propensity_score_matching.html" class="nav-list-link">Propensity Score Matching</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Generalised Least Squares category" aria-pressed="false">
        <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg>
      </button><a href="/Model_Estimation/GLS/GLS.html" class="nav-list-link">Generalised Least Squares</a><ul class="nav-list"><li class="nav-list-item"><a href="/Model_Estimation/GLS/gmm.html" class="nav-list-link">Generalized Method of Moments</a></li><li class="nav-list-item"><a href="/Model_Estimation/GLS/heckman_correction_model.html" class="nav-list-link">Heckman Correction Model</a></li><li class="nav-list-item"><a href="/Model_Estimation/GLS/logit_model.html" class="nav-list-link">Logit Model</a></li><li class="nav-list-item"><a href="/Model_Estimation/GLS/mcfaddens_choice_model.html" class="nav-list-link">McFadden's Choice Model (Alternative-Specific Conditional Logit)</a></li><li class="nav-list-item"><a href="/Model_Estimation/GLS/nested_logit.html" class="nav-list-link">Nested Logit Model</a></li><li class="nav-list-item"><a href="/Model_Estimation/GLS/ordered_probit_logit.html" class="nav-list-link">Ordered Probit/Logit</a></li><li class="nav-list-item"><a href="/Model_Estimation/GLS/probit_model.html" class="nav-list-link">Probit Model</a></li><li class="nav-list-item"><a href="/Model_Estimation/GLS/tobit.html" class="nav-list-link">Tobit Regression</a></li><li class="nav-list-item"><a href="/Model_Estimation/GLS/quantile_regression.html" class="nav-list-link">Quantile Regression</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Multilevel Models category" aria-pressed="false">
        <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg>
      </button><a href="/Model_Estimation/Multilevel_Models/Multilevel_Models.html" class="nav-list-link">Multilevel Models</a><ul class="nav-list"><li class="nav-list-item"><a href="/Model_Estimation/Multilevel_Models/linear_mixed_effects_regression.html" class="nav-list-link">Linear Mixed-Effects Regression</a></li><li class="nav-list-item"><a href="/Model_Estimation/Multilevel_Models/mixed_logit.html" class="nav-list-link">Mixed Logit Model</a></li><li class="nav-list-item"><a href="/Model_Estimation/Multilevel_Models/random_mixed_effects_estimation.html" class="nav-list-link">Random/Mixed Effects in Linear Regression</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Research Design category" aria-pressed="false">
        <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg>
      </button><a href="/Model_Estimation/Research_Design/Research_Design.html" class="nav-list-link">Research Design</a><ul class="nav-list"><li class="nav-list-item"><a href="/Model_Estimation/Research_Design/density_discontinuity_test.html" class="nav-list-link">Density Discontinuity Tests for Regression Discontinuity</a></li><li class="nav-list-item"><a href="/Model_Estimation/Research_Design/event_study.html" class="nav-list-link">Difference in Differences Event Study</a></li><li class="nav-list-item"><a href="/Model_Estimation/Research_Design/instrumental_variables.html" class="nav-list-link">Instrumental Variables</a></li><li class="nav-list-item"><a href="/Model_Estimation/Research_Design/regression_discontinuity_design.html" class="nav-list-link">Regression Discontinuity Design</a></li><li class="nav-list-item"><a href="/Model_Estimation/Research_Design/synthetic_control_method.html" class="nav-list-link">Synthetic Control</a></li><li class="nav-list-item"><a href="/Model_Estimation/Research_Design/two_by_two_difference_in_difference.html" class="nav-list-link">2x2 Difference in Difference</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Statistical Inference category" aria-pressed="false">
        <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg>
      </button><a href="/Model_Estimation/Statistical_Inference/Statistical_Inference.html" class="nav-list-link">Statistical Inference</a><ul class="nav-list"><li class="nav-list-item"><a href="/Model_Estimation/Statistical_Inference/Marginal_Effects_in_Nonlinear_Regression.html" class="nav-list-link">Marginal Effects in Nonlinear Regression</a></li><li class="nav-list-item"><a href="/Model_Estimation/Statistical_Inference/linear_hypothesis_tests.html" class="nav-list-link">Linear Hypothesis Tests</a></li><li class="nav-list-item"><a href="/Model_Estimation/Statistical_Inference/nonlinear_hypothesis_tests.html" class="nav-list-link">Nonlinear Hypothesis Tests</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Nonstandard Errors category" aria-pressed="false">
        <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg>
      </button><a href="/Model_Estimation/Statistical_Inference/Nonstandard_Errors/nonstandard_errors.html" class="nav-list-link">Nonstandard Errors</a><ul class="nav-list"><li class="nav-list-item"><a href="/Model_Estimation/Statistical_Inference/Nonstandard_Errors/bootstrap_se.html" class="nav-list-link">Bootstrap Standard Errors</a></li><li class="nav-list-item"><a href="/Model_Estimation/Statistical_Inference/Nonstandard_Errors/clustered_se.html" class="nav-list-link">Cluster-Robust Standard Errors</a></li><li class="nav-list-item"><a href="/Model_Estimation/Statistical_Inference/Nonstandard_Errors/hc_se.html" class="nav-list-link">Heteroskedasticity-consistent standard errors</a></li></ul></li></ul></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Presentation category" aria-pressed="false">
        <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg>
      </button><a href="/Presentation/Presentation.html" class="nav-list-link">Presentation</a><ul class="nav-list"><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Figures category" aria-pressed="false">
        <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg>
      </button><a href="/Presentation/Figures/Figures.html" class="nav-list-link">Figures</a><ul class="nav-list"><li class="nav-list-item"><a href="/Presentation/Figures/Adding_and_Labeling_a_Reference_Line.html" class="nav-list-link">Adding and Labeling a Reference Line</a></li><li class="nav-list-item"><a href="/Presentation/Figures/Animated_graphs.html" class="nav-list-link">Animated Graphs</a></li><li class="nav-list-item"><a href="/Presentation/Figures/Graph_Annotation.html" class="nav-list-link">Graph Annotations</a></li><li class="nav-list-item"><a href="/Presentation/Figures/Scatterplots.html" class="nav-list-link">Scatterplots</a></li><li class="nav-list-item"><a href="/Presentation/Figures/Styling_Scatterplots.html" class="nav-list-link">Styling Scatterplots</a></li><li class="nav-list-item"><a href="/Presentation/Figures/bar_graphs.html" class="nav-list-link">Bar Graphs</a></li><li class="nav-list-item"><a href="/Presentation/Figures/binscatter.html" class="nav-list-link">Binned Scatterplots</a></li><li class="nav-list-item"><a href="/Presentation/Figures/color_palettes.html" class="nav-list-link">Color Palettes</a></li><li class="nav-list-item"><a href="/Presentation/Figures/density_plots.html" class="nav-list-link">Density Plots</a></li><li class="nav-list-item"><a href="/Presentation/Figures/faceted_graphs.html" class="nav-list-link">Faceted Graphs</a></li><li class="nav-list-item"><a href="/Presentation/Figures/formatting_graph_axes.html" class="nav-list-link">Formatting Graph Axes</a></li><li class="nav-list-item"><a href="/Presentation/Figures/formatting_graph_legends.html" class="nav-list-link">Formatting Graph Legends</a></li><li class="nav-list-item"><a href="/Presentation/Figures/graph_themes.html" class="nav-list-link">Graph Themes</a></li><li class="nav-list-item"><a href="/Presentation/Figures/heatmap_colored_correlation_matrix.html" class="nav-list-link">Heatmap Colored Correlation Matrix</a></li><li class="nav-list-item"><a href="/Presentation/Figures/histograms.html" class="nav-list-link">Histograms</a></li><li class="nav-list-item"><a href="/Presentation/Figures/line_graph_with_labels_at_the_beginning_or_end.html" class="nav-list-link">Line Graph with Labels at the Beginning or End of Lines</a></li><li class="nav-list-item"><a href="/Presentation/Figures/line_graphs.html" class="nav-list-link">Line Graphs</a></li><li class="nav-list-item"><a href="/Presentation/Figures/marginal_effects_plots_for_interactions_with_categorical_variables.html" class="nav-list-link">Marginal effects plots for interactions with categorical variables</a></li><li class="nav-list-item"><a href="/Presentation/Figures/marginal_effects_plots_for_interactions_with_continuous_variables.html" class="nav-list-link">Marginal Effects Plots for Interactions with Continuous Variables</a></li><li class="nav-list-item"><a href="/Presentation/Figures/sankey_diagrams.html" class="nav-list-link">Sankey Diagrams</a></li><li class="nav-list-item"><a href="/Presentation/Figures/scatterplot_by_group_on_shared_axes.html" class="nav-list-link">Scatterplot by Group on Shared Axes</a></li><li class="nav-list-item"><a href="/Presentation/Figures/styling_line_graphs.html" class="nav-list-link">Styling Line Graphs</a></li><li class="nav-list-item"><a href="/Presentation/Figures/summary_graphs.html" class="nav-list-link">Graphing a By-Group or Over-Time Summary Statistic</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Tables category" aria-pressed="false">
        <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg>
      </button><a href="/Presentation/Tables/Tables.html" class="nav-list-link">Tables</a><ul class="nav-list"><li class="nav-list-item"><a href="/Presentation/Tables/Balance_Tables.html" class="nav-list-link">Balance Tables</a></li><li class="nav-list-item"><a href="/Presentation/Tables/Correlation_Matrix.html" class="nav-list-link">Correlation Matrix</a></li><li class="nav-list-item"><a href="/Presentation/Tables/Cross-Tabulation.html" class="nav-list-link">Cross-Tabulation</a></li><li class="nav-list-item"><a href="/Presentation/Tables/Custom_Tables.html" class="nav-list-link">Building Custom Tables</a></li><li class="nav-list-item"><a href="/Presentation/Tables/Regression_Tables.html" class="nav-list-link">Regression Tables</a></li><li class="nav-list-item"><a href="/Presentation/Tables/Summary_Statistics_Tables.html" class="nav-list-link">Summary Statistics Tables</a></li></ul></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Time Series category" aria-pressed="false">
        <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg>
      </button><a href="/Time_Series/Time_Series.html" class="nav-list-link">Time Series</a><ul class="nav-list"><li class="nav-list-item"><a href="/Time_Series/AR-models.html" class="nav-list-link">AR Models</a></li><li class="nav-list-item"><a href="/Time_Series/ARCH_Model.html" class="nav-list-link">ARCH Model</a></li><li class="nav-list-item"><a href="/Time_Series/ARIMA-models.html" class="nav-list-link">ARIMA Models</a></li><li class="nav-list-item"><a href="/Time_Series/ARMA-models.html" class="nav-list-link">ARMA Models</a></li><li class="nav-list-item"><a href="/Time_Series/Autocorrelation_Function.html" class="nav-list-link">Autocorrelation Function</a></li><li class="nav-list-item"><a href="/Time_Series/GARCH_Model.html" class="nav-list-link">GARCH Model</a></li><li class="nav-list-item"><a href="/Time_Series/Granger_Causality.html" class="nav-list-link">Granger Causality</a></li><li class="nav-list-item"><a href="/Time_Series/MA_Model.html" class="nav-list-link">MA Models</a></li><li class="nav-list-item"><a href="/Time_Series/Rolling_Regression.html" class="nav-list-link">Rolling Regression</a></li><li class="nav-list-item"><a href="/Time_Series/State_Space_Models.html" class="nav-list-link">State Space Models</a></li><li class="nav-list-item"><a href="/Time_Series/VAR-models.html" class="nav-list-link">VAR Models</a></li><li class="nav-list-item"><a href="/Time_Series/creating_time_series_dataset.html" class="nav-list-link">Creating a Time Series Dataset</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Other category" aria-pressed="false">
        <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg>
      </button><a href="/Other/Other.html" class="nav-list-link">Other</a><ul class="nav-list"><li class="nav-list-item"><a href="/Other/create_a_conda_package.html" class="nav-list-link">Create a Conda Package (Python)</a></li><li class="nav-list-item"><a href="/Other/get_a_list_of_files.html" class="nav-list-link">Get a List of Files</a></li><li class="nav-list-item"><a href="/Other/import_a_foreign_data_file.html" class="nav-list-link">Import a Foreign Data File</a></li><li class="nav-list-item"><a href="/Other/importing_delimited_files.html" class="nav-list-link">Import a Delimited Data File (CSV, TSV)</a></li><li class="nav-list-item"><a href="/Other/set_a_working_directory.html" class="nav-list-link">Set a Working Directory</a></li><li class="nav-list-item"><a href="/Other/simple_web_scrape.html" class="nav-list-link">Simple Web Scraping</a></li><li class="nav-list-item"><a href="/Other/task_scheduling_with_github_actions.html" class="nav-list-link">Task Scheduling with Github Actions</a></li></ul></li><li class="nav-list-item"><a href="/Desired_Nonexistent_Pages/desired_nonexistent_pages.html" class="nav-list-link">Desired Nonexistent Pages</a></li><li class="nav-list-item"><a href="/Contributing/Contributing.html" class="nav-list-link">Contributing</a></li><li class="nav-list-item"><a href="/" class="nav-list-link">Home</a></li></ul>
</nav>
    <footer class="site-footer">
      This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll.
    </footer>
</div>
  <div class="main" id="top">
    <div id="main-header" class="main-header">
<div class="search" role="search">
  <div class="search-input-wrap">
    <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search LOST" aria-label="Search LOST" autocomplete="off">
    <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label>
  </div>
  <div id="search-results" class="search-results"></div>
</div>
</div>
    <div class="main-content-wrap">
      <nav aria-label="Breadcrumb" class="breadcrumb-nav">
  <ol class="breadcrumb-nav-list">
    <li class="breadcrumb-nav-list-item"><a href="/Machine_Learning/Machine_Learning.html">Machine Learning</a></li>
    <li class="breadcrumb-nav-list-item"><span>Decision Trees</span></li>
  </ol>
</nav>
      <div id="main-content" class="main-content">
        <main>
            <h1 id="decision-trees">
    <a href="#decision-trees" class="anchor-heading" aria-labelledby="decision-trees"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Decision Trees
</h1>
<p>Decision trees are among the most common and useful machine learning methodologies. While they are a relatively simple method, they are incredibly easy to understand and implement for both classification and regression problems.</p>
<p>A decision tree “grows” by creating a cutoff point (often called a split) at a single point in the data that maximizes accuracy. The tree’s prediction is then based on the mean of the region that results from the input data.</p>
<p>For both regression and classification trees, it is important to optimize the number of splits that we allow the tree to make. If there is no limit, the trees would be able to create as many splits as the data will allow. This would mean the tree could perfectly “predict” every value from the training dataset, but would perform terribly out of sample (i.e., overfit the data). As such, it is important to keep a reasonable limit on the number of splits. This is achieved by creating a penalty that the algorithm has to pay in order to perform another split. If the increase in accuracy is worth more than the penalty, it will make the split.</p>
<p>For regression trees, the decision to split along a continuum of values is often made by minimizing the residual sum of squares:</p>
\[minimize \sum(y-prediction)^2\]
<p>This should be highly reminiscent of ordinary least squares. Where this differs is in the number of splits created, the binary nature of the splits, and its nonlinear nature.</p>
<p>The methodology behind classificiation is very similar, except the splits are decided by minimizing purity, such as the Gini index:</p>
\[G= 1 - \sum_{i = 1}^{C} (p_{i})^2\]
<p>The goal here is to create regions with as of classifications as possible, as such, a smaller Gini index implies a more pure region.</p>
<h2 id="keep-in-mind">
    <a href="#keep-in-mind" class="anchor-heading" aria-labelledby="keep-in-mind"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Keep in Mind
</h2>
<ul>
  <li>While decision trees are easy to interpret and understand, they often underpreform relative to other machine learning methodologies.</li>
  <li>Even though they may not offer the best predictions, decision trees excel at identifying key variables in the data.</li>
</ul>
<h2 id="also-consider">
    <a href="#also-consider" class="anchor-heading" aria-labelledby="also-consider"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Also Consider
</h2>
<ul>
  <li>Decision trees are the basis for all tree-based methodologies. More robust methods, such as <a href="/Machine_Learning/random_forest.html">Random Forests</a>, are a collection of decision trees that aggregate their decisions into a single prediction. These forests are often more useful for predictive modeling.</li>
</ul>
<h1 id="implementations">
    <a href="#implementations" class="anchor-heading" aria-labelledby="implementations"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Implementations
</h1>
<h2 id="python">
    <a href="#python" class="anchor-heading" aria-labelledby="python"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Python
</h2>
<p>The easiest way to get started with decision trees in Python is to use the <a href="https://scikit-learn.org/stable/index.html"><strong>scikit-learn</strong></a> package. In the example below, we’ll use data on the passengers of the Titanic to build a classification tree that predicts whether passengers survived or not (binary outcome) based on
properties such as passenger age, gender as recorded in the data, and class of cabin. As ever with machine learning, it’s essential that an out-of-sample set, also known as a test set, is retained and used to score the final model.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Install sklearn and pandas using pip or conda, if you don't have them already.
# Note that the 'f-strings' used in the print statements below are only available in Python&gt;=3.6.
</span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">tree</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">plot_confusion_matrix</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="n">titanic</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"https://raw.githubusercontent.com/Evanmj7/Decision-Trees/master/titanic.csv"</span><span class="p">,</span>
                      <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Let's ensure the columns we want to treat as continuous are indeed continuous by using pd.to_numeric
# The errors = 'coerce' keyword argument will force any values that cannot be
# cast into continuous variables to become NaNs.
</span><span class="n">continuous_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s">'age'</span><span class="p">,</span> <span class="s">'fare'</span><span class="p">]</span>
<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">continuous_cols</span><span class="p">:</span>
    <span class="n">titanic</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">to_numeric</span><span class="p">(</span><span class="n">titanic</span><span class="p">[</span><span class="n">col</span><span class="p">],</span> <span class="n">errors</span><span class="o">=</span><span class="s">'coerce'</span><span class="p">)</span>

<span class="c1"># Set categorical cols &amp; convert to dummies
</span><span class="n">cat_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s">'sex'</span><span class="p">,</span> <span class="s">'pclass'</span><span class="p">]</span>
<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">cat_cols</span><span class="p">:</span>
    <span class="n">titanic</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">titanic</span><span class="p">[</span><span class="n">col</span><span class="p">].</span><span class="n">astype</span><span class="p">(</span><span class="s">'category'</span><span class="p">).</span><span class="n">cat</span><span class="p">.</span><span class="n">codes</span>

<span class="c1"># Clean the dataframe. An alternative would be to retain some rows with missing values by giving
# a special value to nan for each column, eg by imputing some values, but one should be careful not to
# use information from the test set to impute values in the training set if doing this. Strictly speaking,
# we shouldn't be dropping the nans from the test set here (as we pretend we don't know what's in it) - but
# for the sake of simplicity, we will.
</span><span class="n">titanic</span> <span class="o">=</span> <span class="n">titanic</span><span class="p">.</span><span class="n">dropna</span><span class="p">()</span>

<span class="c1"># Create list of regressors
</span><span class="n">regressors</span> <span class="o">=</span> <span class="n">continuous_cols</span> <span class="o">+</span> <span class="n">cat_cols</span>
<span class="c1"># Predicted var
</span><span class="n">y_var</span> <span class="o">=</span> <span class="p">[</span><span class="s">'survived'</span><span class="p">]</span>

<span class="c1"># Create a test (25% of data) and train set
</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">titanic</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span>

<span class="c1"># Now let's create an empty decision tree to solve the classification problem:
</span><span class="n">clf</span> <span class="o">=</span> <span class="n">tree</span><span class="p">.</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">min_samples_split</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                                  <span class="n">ccp_alpha</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="c1"># The last option, ccp_alpha, prunes low-value complexity from the tree to help
# avoid overfitting.
</span>
<span class="c1"># Fit the tree with the data
</span><span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">regressors</span><span class="p">],</span> <span class="n">train</span><span class="p">[</span><span class="n">y_var</span><span class="p">])</span>

<span class="c1"># Let's take a look at the tree:
</span><span class="n">tree</span><span class="p">.</span><span class="n">plot_tree</span><span class="p">(</span><span class="n">clf</span><span class="p">)</span>

<span class="c1"># How does it perform on the train and test data?
</span><span class="n">train_accuracy</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">clf</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">regressors</span><span class="p">],</span> <span class="n">train</span><span class="p">[</span><span class="n">y_var</span><span class="p">]),</span> <span class="mi">4</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">f'Accuracy on train set is </span><span class="si">{</span><span class="n">train_accuracy</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>

<span class="n">test_accuracy</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">clf</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="n">regressors</span><span class="p">],</span> <span class="n">test</span><span class="p">[</span><span class="n">y_var</span><span class="p">]),</span> <span class="mi">4</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">f'Accuracy on test set is </span><span class="si">{</span><span class="n">test_accuracy</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>

<span class="c1"># Show the confusion matrix
</span><span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">test</span><span class="p">[</span><span class="n">regressors</span><span class="p">],</span> <span class="n">test</span><span class="p">[</span><span class="n">y_var</span><span class="p">])</span>

<span class="c1"># Although it won't be the same from run to run, this model scored around 80%
# out of sample, and has slightly more false positives than false negatives.
</span></code></pre></div></div>
<h2 id="r">
    <a href="#r" class="anchor-heading" aria-labelledby="r"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> R
</h2>
<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Load packages</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">rpart</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">rpart.plot</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">caret</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">rattle</span><span class="p">)</span><span class="w">
</span><span class="c1"># We will utilize data regarding passengers on their survival. We have multiple pieces of information on every passenger, including passenger age, sex, cabin number, and class.</span><span class="w">

</span><span class="c1"># Our goal is to build a decision tree that can predict whether or not passengers survived the wreck, making it a classification tree. These same methodologies can be used and applied to a regression tree framework.</span><span class="w">

</span><span class="c1"># Read in the data</span><span class="w">
</span><span class="n">titanic</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">read.csv</span><span class="p">(</span><span class="s2">"https://raw.githubusercontent.com/Evanmj7/Decision-Trees/master/titanic.csv"</span><span class="p">)</span><span class="w">

</span><span class="c1"># Set a seed for reproducability</span><span class="w">
</span><span class="n">set.seed</span><span class="p">(</span><span class="m">1234</span><span class="p">)</span><span class="w">

</span><span class="c1"># The data is clean for the most part, but some variables have been read in as factors instead of numeric variables, so we can fix that with the following code.</span><span class="w">
</span><span class="n">titanic</span><span class="o">$</span><span class="n">age</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">as.numeric</span><span class="p">(</span><span class="n">titanic</span><span class="o">$</span><span class="n">age</span><span class="p">)</span><span class="w">
</span><span class="n">titanic</span><span class="o">$</span><span class="n">fare</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">as.numeric</span><span class="p">(</span><span class="n">titanic</span><span class="o">$</span><span class="n">fare</span><span class="p">)</span><span class="w">

</span><span class="c1"># As with all machine learning methodologies, we want to create a test and a training dataset</span><span class="w">

</span><span class="c1"># Take a random sample of the data, here we have chosen to use 75% for training and 25% for validation</span><span class="w">
</span><span class="n">samp_size</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">floor</span><span class="p">(</span><span class="m">0.75</span><span class="o">*</span><span class="n">nrow</span><span class="p">(</span><span class="n">titanic</span><span class="p">))</span><span class="w">
</span><span class="n">train_index</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sample</span><span class="p">(</span><span class="nf">seq_len</span><span class="p">(</span><span class="n">nrow</span><span class="p">(</span><span class="n">titanic</span><span class="p">)),</span><span class="n">size</span><span class="o">=</span><span class="n">samp_size</span><span class="p">,</span><span class="n">replace</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">)</span><span class="w">

</span><span class="n">train</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">titanic</span><span class="p">[</span><span class="n">train_index</span><span class="p">,</span><span class="w"> </span><span class="p">]</span><span class="w">
</span><span class="n">test</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">titanic</span><span class="p">[</span><span class="o">-</span><span class="n">train_index</span><span class="p">,</span><span class="w"> </span><span class="p">]</span><span class="w">

</span><span class="c1"># Now that we have our test and train datasets, we can build our trees. Here, we will use the package "rpart". Other packages, such as "ranger" are also viable options.</span><span class="w">

</span><span class="c1"># Here we can pick some variables we think would be good, the tree will decide which ones are best. Some data we have isn't useful, such as an individual's name or the random ID we assigned passengers, so there is no need to include them.</span><span class="w">

</span><span class="n">basic_tree</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">rpart</span><span class="p">(</span><span class="w">
  </span><span class="n">survived</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">pclass</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">sex</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">age</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">fare</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">embarked</span><span class="p">,</span><span class="w"> </span><span class="c1"># our formula</span><span class="w">
  </span><span class="n">data</span><span class="o">=</span><span class="n">train</span><span class="p">,</span><span class="w">
  </span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"class"</span><span class="p">,</span><span class="w"> </span><span class="c1"># tell the model we are doing classification</span><span class="w">
  </span><span class="n">minsplit</span><span class="o">=</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="c1"># set a minimum number of splits</span><span class="w">
  </span><span class="n">cp</span><span class="o">=</span><span class="m">.02</span><span class="w"> </span><span class="c1"># set an optional penalty rate. It is often useful to try out many different ones, use the caret package to test many at once</span><span class="w">
</span><span class="p">)</span><span class="w">

</span><span class="n">basic_tree</span><span class="w">

</span><span class="c1"># plot it using the packages we loaded above</span><span class="w">
</span><span class="n">fancyRpartPlot</span><span class="p">(</span><span class="n">basic_tree</span><span class="p">,</span><span class="n">caption</span><span class="o">=</span><span class="s2">"Basic Decision Tree"</span><span class="p">)</span><span class="w">

</span><span class="c1"># This plot gives a very intuitive visual representation on what is going on behind the scenes.</span><span class="w">

</span><span class="c1"># Now we should predict using the test data we left out!</span><span class="w">
</span><span class="n">predictions</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">predict</span><span class="p">(</span><span class="n">basic_tree</span><span class="p">,</span><span class="n">newdata</span><span class="o">=</span><span class="n">test</span><span class="p">,</span><span class="n">type</span><span class="o">=</span><span class="s2">"class"</span><span class="p">)</span><span class="w">

</span><span class="c1"># Make the numeric responses as well as the variables that we are testing on into factors</span><span class="w">
</span><span class="n">predictions</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">as.factor</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span><span class="w">
</span><span class="n">test</span><span class="o">$</span><span class="n">survived</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">as.factor</span><span class="p">(</span><span class="n">test</span><span class="o">$</span><span class="n">survived</span><span class="p">)</span><span class="w">

</span><span class="c1"># Create a confusion matrix which tells us how well we did.</span><span class="w">
</span><span class="n">confusionMatrix</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span><span class="n">test</span><span class="o">$</span><span class="n">survived</span><span class="p">)</span><span class="w">

</span><span class="c1"># This particular model got ~80% accuracy. This varies each time if you do not set a seed. Much better than a coin toss, but not great. With some additional tuning a decision tree can be much more accurate! Try it for yourself by changing the factors that go into the prediction and the penalty rates.</span><span class="w">

</span></code></pre></div></div>
        </main>
  <hr>
  <footer>
      <div class="d-flex mt-2">
          <p class="text-small text-grey-dk-000 mb-0">
            <a href="https://github.com/lost-stats/lost-stats.github.io/edit/source/Machine_Learning/decision_trees.md" id="edit-this-page">Edit this page on GitHub.</a>
          </p>
      </div>
  </footer>
      </div>
    </div>
<div class="search-overlay"></div>
  </div>
</body>
</html>
